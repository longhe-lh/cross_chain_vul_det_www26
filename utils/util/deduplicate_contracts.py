import os
import shutil

import chardet
from codebase_to_text import CodebaseToText

from eblg_build.eblg_helper import validate_and_refine_until_passed
from utils.llm_helper.analyzer import analyze_bridge_contract
from utils.util.util import batch_convert_all_to_gbk


def collect_contracts_and_run_analysis(input_root, output_root, model_type):
    for bridge_name in os.listdir(input_root):
        bridge_path = os.path.join(input_root, bridge_name)
        contract_path = os.path.join(bridge_path, "contract")

        if not os.path.isdir(contract_path):
            print(f"âŒ Skipped {bridge_name}: no contract folder")
            continue

        # è¾“å‡º BridgeX ç›®å½•å’Œ contracts å­ç›®å½•
        output_bridge_dir = os.path.join(output_root, bridge_name)
        contracts_dir = os.path.join(output_bridge_dir, "contracts")
        os.makedirs(contracts_dir, exist_ok=True)

        seen_files = set()

        # å¤åˆ¶å”¯ä¸€åˆçº¦æ–‡ä»¶
        for dirpath, _, filenames in os.walk(contract_path):
            for file_name in filenames:
                if not file_name.endswith(".sol"):
                    continue
                if file_name in seen_files:
                    continue

                seen_files.add(file_name)
                src_file = os.path.join(dirpath, file_name)
                dst_file = os.path.join(contracts_dir, file_name)
                shutil.copy2(src_file, dst_file)

        # åˆå¹¶ä¸º BridgeX.txt
        merged_txt_path = os.path.join(output_bridge_dir, f"{bridge_name}.txt")

        code_to_text = CodebaseToText(
            input_path=contracts_dir,
            output_path=merged_txt_path,
            output_type="txt",
            verbose=True,
            exclude_hidden=True
        )
        batch_convert_all_to_gbk(contracts_dir)
        code_to_text.get_file()

        # è¯»å–åˆçº¦æ–‡æœ¬å†…å®¹
        try:
            # with open(merged_txt_path, 'r', encoding='gbk') as f:
            #     contract_code = f.read()

            with open(merged_txt_path, 'rb') as f:
                contract_code = f.read()
            with open(merged_txt_path, 'r', encoding=chardet.detect(contract_code)['encoding']) as f1:
                contract_code = f1.read()

        except Exception as e:
            print(f"âŒ Failed to read {merged_txt_path}: {e}")
            continue

        # æ‰§è¡Œåˆ†æå’ŒéªŒè¯
        try:
            print(f"ğŸš€ Analyzing {bridge_name}...")
            output_json_path = os.path.join(output_bridge_dir, f"{bridge_name}.json")

            analyze_bridge_contract(
                contract_code,
                bridge_name=bridge_name,
                model_type=model_type,
                output=output_json_path,
                report=True
            )

            print(f"ğŸ›  Validating {bridge_name}...")
            validate_and_refine_until_passed(
                contract_code=contract_code,
                bridge_name=bridge_name,
                output_pro_dir_path=output_bridge_dir,
                bridge_dir_path=os.path.join(output_bridge_dir, "contracts"),
                max_attempts=10
            )

            print(f"âœ… {bridge_name} analysis complete.\n")

        except Exception as e:
            print(f"âŒ Error processing {bridge_name}: {e}")

    print("ğŸ‰ All bridges processed.\n")


if __name__ == "__main__":
    # è¾“å…¥è·¯å¾„
    input_bridges_root = r"D:\LongHe\01-PHD\02-åŸºäºLLMçš„è·¨é“¾æ¼æ´æ£€æµ‹\10-data-deduplicate\test_20250721\non_vul_bridges"
    # æ•´ç†åçš„è¾“å‡ºè·¯å¾„
    output_collected_root = r"D:\LongHe\01-PHD\02-åŸºäºLLMçš„è·¨é“¾æ¼æ´æ£€æµ‹\10-data-deduplicate\test_20250721\dedup_non_vul_bridges"
    # åˆ†ææ¨¡å‹ç±»å‹æ ‡è¯†
    model_type = "Qwen/QwQ-32B"

    collect_contracts_and_run_analysis(
        input_root=input_bridges_root,
        output_root=output_collected_root,
        model_type=model_type
    )
