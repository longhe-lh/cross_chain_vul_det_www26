{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 12438243,
     "sourceType": "datasetVersion",
     "datasetId": 7845921
    }
   ],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers accelerate peft bitsandbytes trl\n",
    "!pip install datasets deepspeed"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2025-07-11T11:12:19.091682Z",
     "iopub.execute_input": "2025-07-11T11:12:19.092349Z",
     "iopub.status.idle": "2025-07-11T11:12:26.088184Z",
     "shell.execute_reply.started": "2025-07-11T11:12:19.092322Z",
     "shell.execute_reply": "2025-07-11T11:12:26.087433Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def format_prompt(example):\n",
    "    prompt = f\"{example['instruction']}\\n{example['input']}\\n\\n### Response:\\n\"\n",
    "    label = example['output']\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"/kaggle/input/train-data/sft_data.jsonl\")\n",
    "dataset = dataset.map(format_prompt)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-11T11:12:26.089905Z",
     "iopub.execute_input": "2025-07-11T11:12:26.090184Z",
     "iopub.status.idle": "2025-07-11T11:12:27.591327Z",
     "shell.execute_reply.started": "2025-07-11T11:12:26.090159Z",
     "shell.execute_reply": "2025-07-11T11:12:27.590356Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_prompt(example):\n",
    "    prompt = example[\"prompt\"]\n",
    "    label = example[\"label\"]\n",
    "\n",
    "    prompt_tokens = tokenizer(prompt, truncation=True, max_length=1024)\n",
    "    label_tokens = tokenizer(label, truncation=True, max_length=1024)\n",
    "    prompt_ids = prompt_tokens[\"input_ids\"]\n",
    "    label_ids = label_tokens[\"input_ids\"]\n",
    "\n",
    "    # print(f\"\\n=== Sample ID: {example.get('id', 'N/A')} ===\")\n",
    "    # print(f\"Prompt length: {len(prompt_ids)} (truncated: {prompt_tokens.get('truncated', False)})\")\n",
    "    # print(f\"Label length: {len(label_ids)} (truncated: {label_tokens.get('truncated', False)})\")\n",
    "    # print(f\"Total combined length before truncation: {len(prompt_ids) + len(label_ids)}\")\n",
    "\n",
    "    input_ids = prompt_ids + label_ids\n",
    "    input_ids = input_ids[:2048]\n",
    "\n",
    "    labels = [-100] * len(prompt_ids) + label_ids\n",
    "    labels = labels[:2048]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": [1] * len(input_ids)\n",
    "    }\n",
    "    \n",
    "tokenized_dataset = dataset[\"train\"].map(tokenize_prompt, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\":0},\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-11T11:12:27.592136Z",
     "iopub.execute_input": "2025-07-11T11:12:27.592598Z",
     "iopub.status.idle": "2025-07-11T11:13:01.159232Z",
     "shell.execute_reply.started": "2025-07-11T11:12:27.592570Z",
     "shell.execute_reply": "2025-07-11T11:13:01.158322Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/deepseek_lora_output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=4,\n",
    "    logging_steps=5,           \n",
    "    save_steps=10,\n",
    "    report_to=\"none\",         \n",
    "    run_name=\"deepseek_lora\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    args=training_args,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-11T11:13:01.160741Z",
     "iopub.execute_input": "2025-07-11T11:13:01.161051Z",
     "iopub.status.idle": "2025-07-11T11:13:02.970070Z",
     "shell.execute_reply.started": "2025-07-11T11:13:01.161019Z",
     "shell.execute_reply": "2025-07-11T11:13:02.969271Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Number of training samples:\", len(trainer.train_dataset))\n",
    "print(\"Start training...\")\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-11T11:13:02.970896Z",
     "iopub.execute_input": "2025-07-11T11:13:02.971155Z",
     "iopub.status.idle": "2025-07-11T11:21:13.750719Z",
     "shell.execute_reply.started": "2025-07-11T11:13:02.971137Z",
     "shell.execute_reply": "2025-07-11T11:21:13.749849Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/kaggle/working/deepseek_lora_output\")\n",
    "model.eval()\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"/kaggle/input/train-data/sft_data.jsonl\")[\"train\"]\n",
    "\n",
    "def extract_label(text):\n",
    "    if \"Label: Yes\" in text:\n",
    "        return \"Yes\"\n",
    "    elif \"Label: No\" in text:\n",
    "        return \"No\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for sample in test_dataset:\n",
    "    prompt = f\"{sample['instruction']}\\n{sample['input']}\\n\\nRespond concisely in 2-3 sentences explaining whether a vulnerability exists, then write: Label: Yes or Label: No.\\n\\n### Response:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda:0\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    gen_ids = outputs[0][input_len:]\n",
    "    gen_text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "    pred_label = extract_label(gen_text)\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(sample,output_text)\n",
    "    true_label = \"Yes\" if \"Label: Yes\" in sample[\"output\"] else \"No\"\n",
    "\n",
    "    total += 1\n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "\n",
    "    print(f\"[{total}] pred: {pred_label}, true: {true_label}\")\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nAccuracy: {accuracy:.2%} ({correct}/{total})\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-11T11:21:13.751783Z",
     "iopub.execute_input": "2025-07-11T11:21:13.752071Z",
     "iopub.status.idle": "2025-07-11T11:31:03.261936Z",
     "shell.execute_reply.started": "2025-07-11T11:21:13.752049Z",
     "shell.execute_reply": "2025-07-11T11:31:03.261211Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
