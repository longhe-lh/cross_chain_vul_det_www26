{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 12543759,
     "sourceType": "datasetVersion",
     "datasetId": 7885660
    },
    {
     "sourceId": 12549726,
     "sourceType": "datasetVersion",
     "datasetId": 7919504
    }
   ],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "from datasets import load_dataset\n\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/multi-qwen-test/sft_data_multi_templates_gpt_text3_deepseek70_qwen4_train.jsonl\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-23T05:56:18.818570Z",
     "iopub.execute_input": "2025-07-23T05:56:18.819330Z",
     "iopub.status.idle": "2025-07-23T05:56:19.997525Z",
     "shell.execute_reply.started": "2025-07-23T05:56:18.819299Z",
     "shell.execute_reply": "2025-07-23T05:56:19.996873Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# 加载 Qwen 模型和 tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-23T05:56:19.998229Z",
     "iopub.execute_input": "2025-07-23T05:56:19.999090Z",
     "iopub.status.idle": "2025-07-23T05:56:30.828538Z",
     "shell.execute_reply.started": "2025-07-23T05:56:19.999064Z",
     "shell.execute_reply": "2025-07-23T05:56:30.827711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2025-07-23 05:56:25.329878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753250185.352381     787 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753250185.359328     787 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "# Tokenization\ndef tokenize_prompt(example):\n    prompt = example[\"prompt\"]\n    label = example[\"label\"]\n\n    prompt_tokens = tokenizer(prompt, truncation=True, max_length=2048)\n    label_tokens = tokenizer(label, truncation=True, max_length=2048)\n    prompt_ids = prompt_tokens[\"input_ids\"]\n    label_ids = label_tokens[\"input_ids\"]\n\n    input_ids = prompt_ids + label_ids\n    input_ids = input_ids[:4096]\n\n    labels = [-100] * len(prompt_ids) + label_ids\n    labels = labels[:4096]\n\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": labels,\n        \"attention_mask\": [1] * len(input_ids)\n    }\ntokenized_dataset = dataset[\"train\"].map(tokenize_prompt, remove_columns=dataset[\"train\"].column_names)\n\n\n# 加载模型 + 应用LoRA配置\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    load_in_4bit=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\nmodel = prepare_model_for_kbit_training(model)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-23T05:56:30.834940Z",
     "iopub.execute_input": "2025-07-23T05:56:30.835143Z",
     "iopub.status.idle": "2025-07-23T05:56:53.134380Z",
     "shell.execute_reply.started": "2025-07-23T05:56:30.835127Z",
     "shell.execute_reply": "2025-07-23T05:56:53.133709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5cdc4aa9ce549ff8bc72bf34641b27b"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/qwen_lora_output\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=5,\n",
    "    save_steps=80,\n",
    "    report_to=\"none\",\n",
    "    run_name=\"qwen_lora\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    ")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-23T05:56:53.140227Z",
     "iopub.execute_input": "2025-07-23T05:56:53.140424Z",
     "iopub.status.idle": "2025-07-23T05:56:53.354865Z",
     "shell.execute_reply.started": "2025-07-23T05:56:53.140408Z",
     "shell.execute_reply": "2025-07-23T05:56:53.354240Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "# 训练模型\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=tokenized_dataset,\n    args=training_args,\n)\n\nprint(\"Number of training samples:\", len(trainer.train_dataset))\nprint(\"Start training...\")\ntrainer.train()\ntrainer.save_model()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-23T05:56:53.355739Z",
     "iopub.execute_input": "2025-07-23T05:56:53.355939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[2025-07-23 05:56:53,849] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/bin/ld: cannot find -laio: No such file or directory\ncollect2: error: ld returned 1 exit status\n/usr/bin/ld: cannot find -laio: No such file or directory\ncollect2: error: ld returned 1 exit status\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[2025-07-23 05:56:55,296] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Number of training samples: 246\nStart training...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='233' max='615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [233/615 49:13 < 1:21:23, 0.08 it/s, Epoch 1.89/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>1.631800</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.750500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.530000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.562300</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.397800</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.351400</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.371900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.317900</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.192000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.249300</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.223700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.356800</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.253800</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.083500</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.204800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.116400</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>1.179700</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.278500</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>1.066300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.086600</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>1.131200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.082500</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>1.056100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.997700</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.018600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.043200</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.920200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.797700</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.893900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.936600</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.831500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.724800</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.871200</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.873500</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.800500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.736200</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.872500</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.656500</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.583300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.654800</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.843500</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.583400</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.857600</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.551400</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.691200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.566900</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import json\nimport re\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nimport torch\n\n# 加载 base 模型和 LoRA 权重\nmodel_name = \"Qwen/Qwen2.5-7B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    load_in_4bit=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\nmodel = PeftModel.from_pretrained(base_model, \"/kaggle/working/qwen_lora_output\")\nmodel.eval()\n\n# 加载测试集\ntest_dataset = load_dataset(\"json\", data_files=\"/kaggle/input/multi-qwen-test/sft_data_multi_templates_gpt_text3_deepseek70_qwen4_test.jsonl\")[\"train\"]\n\n# label 提取函数\ndef extract_label(text: str) -> str:\n    match = re.search(r\"Label:\\s*(Yes|No)\", text, re.IGNORECASE)\n    if match:\n        return match.group(1).capitalize()\n    return \"Unknown\"\n\n# 推理与评估\ncorrect = 0\ntotal = 0\n\nfor sample in test_dataset:\n    prompt = sample[\"prompt\"]\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).to(\"cuda:0\")\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=2048,\n            do_sample=False,\n            temperature=0.0,\n            pad_token_id=tokenizer.pad_token_id\n        )\n\n    input_len = inputs[\"input_ids\"].shape[1]\n    gen_ids = outputs[0][input_len:]\n    gen_text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n    pred_label = extract_label(gen_text)\n\n    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(\"output_text\", \"---\"*10, \"\\n\", output_text)\n\n    true_label = \"Yes\" if \"Label: Yes\" in sample[\"label\"] else \"No\"\n\n    total += 1\n    if pred_label == true_label:\n        correct += 1\n\n    print(f\"pred: {pred_label}, true: {true_label}\")\n    print(f\"total: {total}, correct: {correct}\")\n\n# 准确率输出\naccuracy = correct / total\nprint(f\"\\nAccuracy: {accuracy:.2%} ({correct}/{total})\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
